### Deliver a report that considers the ways in which the software engineering process can be measured and assessed in terms of measurable data, an overview of the computational platforms available to perform this work, the algorithmic approaches available, and the ethics concerns surrounding this kind of analytics.

The use of social tools and technologies has become mainstream in the enterprise and many companies that have already invested in such tools are beginning to see visible, positive returns[1]. With more and more companies adopting mobile tech such as mobile email apps and messaging services, the working day has extended even past the typical 9-5 and employees are nearly on call in case of emergency. Companies are seeing social benefits to this increasing use of tools such as reduced costs, increased productivity and enhanced organization. While we have seen many technological developments in  companies in order to automate their everyday task, one place we haven't seen many developments is the measuring of the people who make all these tools, software engineers. There are many reasons for this but I think the main one is because software development is such a new field we are still working on understanding the ins and outs of managing it, also the managers tend to be from business (or maybe business in technology) backgrounds, so us software engineers are faced with the difficult task of explaining how we do our jobs to our higher ups. Another reason for the lack of software development measures is limits on our technology, I will talk about this in more detail later, but basically what I mean by this is we are only now understanding neural networks and AI enough to create tools that can measure our code efficiency, complexity and behaviour.
	
I interviewed my dad, who is currently a program manager for Amazon, and he had some very interesting things to say with regard to the problem addressed. The points he makes are with reference to network engineers but can be equally stated as software engineering problems as well. “Coincidentally this is a real problem faced by many high tech companies today, in the old days companies like Amazon who were retail companies, could quantify their productivity per individual by physically looking at the pallet beside them and counting the number of boxes on the pallet. However now as Amazon has become one of the biggest companies in the world and has diversified into new fields such as cloud storage and data centres with their Amazon Web Services branch their employees are nearly 100% software and network engineers. The traditional managers in Amazon now struggle to understand how much headcount they need to run their business as it is very difficult to quantify the productivity of technical engineers using traditional methods as there are no physical outputs produced.”. These big tech companies are now hiring more non-conventional managers, i.e. managers that do not come for business backgrounds. For example my dad used to work for Ericssons setting up the cellular network in Ireland, he then moved to AWS a few years ago as a technical project manager but now he is a program manager for the IT deployment in fulfillment centres. Rather than recruiting someone with no technical background for these technical jobs, Amazon, Google and the likes recruit people from technical backgrounds who have the personality of a leader as they are much more efficient in understanding the field they are in, thus they are able to measure the productivity of their employees much more effectively. “They have introduced metrics into the deliverance of software engineers and these metrics have to take into account the progress the team is making. Methods that programmers use such as SCRUM and AGILE development cause the traditional managers headaches as they by their definition it is very difficult to judge the project if you are not stuck in the day to day details. Hence we have to find a way to report upwards to managers who are not in technological details of the project”. I think this is a very good point as it indirectly describes the problem of hiring traditional/non-technical managers, when you have someone who does not understand the work of their employees, how they are supposed to report on the project at hand and how they are supposed to measure the project/employees progress. While it is  not feasible to have a companies entire management board made up of technical people with no business background, I think managers should have varying level of technical knowledge depending on how involved they are with the project  “One way we do this today is discussing the evolutionary phase of a software project and making sure that everyone in the organization understands the phases and no matter what project it is, we report into the phases. It's almost like a coding standard but for reporting and measuring progress. The phases are the initiation phase , planning phase, scoping, testing, trial and correction phase and these phases go for whether the project is a data centre, fulfillment centre or software service, Sometimes phases aren't delivered in time, the traditional manager would mark this as a problem for the team as traditional managers expect a linear progression of time vs output but unfortunately programming doesn't work like that. It has its ups and downs, trials, errors and correction phases etc… so output is never linear”. This is especially valid with the recent idea of little and often over time (such as software updates). What we have to do in software engineering is to be able to measure our progress through the use of metrics (these metrics will be discussed later on), “Amazon tried to address this issue by what they call daily stand up meetings, every morning the entire team would have a brief 15-30 minute meeting instead of the traditional 3 hour meeting at the start, midway through and at the end of the project. This was in order to inform managers about more minor but still relevant details and that the team is still on track.”. As managers are now being brought into the minor details of the project they also need to have a relevant technical background as they need to be able to understand these metrics and details in order to measure the teams success.

With the field of computer science experiencing exponential growth, increasing capabilities, increasing pervasiveness and increasing connectivity we are seeing the world depend more and more on the internet and software. For the past decade we have seen a growth in the way professions use technology. Doctors are now using skype to talk to patients (we also have WebMD to self-diagnose and find out if its beneficial to go to the doctor), we are seeing architects using software to design more complex buildings, teachers and professors using online resources such as zoom, BlackBoard etc… and students self-learning using Khan Academy and Udemy. The most online sporting journalism is Bleacher Report with 22 million active users a month, rivalling the more traditional methods such as CNN sports. Lawyers are using online software such as zoom and email services to grant quicker legal advice. Technology is even infiltrating the world of religion, which is especially evident with COVID-19, mass is being offered online. There is also another software called Second Life. Second Life is an internet-based, 3-D virtual world constantly evolving by the work of its millions of users. In Second Life there are churches: Protestant, Catholic, Orthodox and more[2]. We are moving from bespoke services to decomposition routinization. This sees the breaking down of complex, professional work in order to identify the parts a computer can do resulting in the professional be it a doctor, lawyer, nurse anything being able to focus more on the significant tasks at hand, thus helping more and more people. I think with the increasing importance, capabilities and dependence on the internet and software resulting in the lives of other being made easier or possibly even changing a life by a doctor not wasting time on a diagnosis or lawyer accidentally missing something we need to come up with new ways to measure software engineering and the products that we produce that can change society. I think this because what is going to come next in technology is the use of big data (it is believed that data science is going to be more valued than medicinal science in the near future), complex problem solving algorithms, affective computing (computer detecting human emotions), robotics (self driving cars), cognitive computing (neural networks) with all the advances that could be made we need to ensure that the technology we develop is morally acceptable and does not corrupt society as we know it.

Software has been around since the 1940’s and became predominant 1960’s with Apollo 11, how is it that we have not come up with an effective way to measure software engineering yet? While this isn't entirely true we have come up with ways to measure software engineering but until the mid-1990’s, most software engineering metrics
were designed for use at the organizational [3] rather than on a single project or individual level. I think the reason that we haven't found an effective way to measure software engineering as of yet is limits in our technology (from the 1940s-2000s), when the industry of software was exploding the computers were not capable of measuring the data that we need to measure in order to measure software engineering. However with the first wave of AI emerging in the 1960s, engineers saw they needed a way to measure their productivity realising the impact these new AI tools may have on society. The first wave of AI was basic follow the path algorithms like if this then do that, else do that which would progress down a list of these and result in an answer. One of the most significant examples of a program like this was the Latent Damage Law Expert System, which was a program with thousands of branches that would result in an outcome being processed, which would mean that everyone would get a fair punishment. Systems like this also took place in medicine, tax auditing, consulting etc… With these new advances software engineers had to start measuring their progress in order to create effective programs. In 1980 the first measuring tool was adopted, called PSP, PSP was an entirely handwritten report which involved just filling out a report and it really measured organizational details rather than project or an individual.
The 1990s saw the emergence of a second wave of AI, which aimed to create an AI system that can judge more effectively than a human. This was a big change in the AI field as computers were now taking why into account rather than just do this. This is making machines more capable and taking on more of today's tasks. With reference to measuring software engineering this is very important as now we are seeing the emergence of a technology that can take into account why this is happening, meaning it can take on many more significant roles so the people designing these technologies need to have programmed it effectively and eliminate all potential bugs, corruptions and faults. But also now that technologies like this exist we can create software tools to measure software engineering. However it would not be another 3 decades until computers were capable of using these new AI tools to measure software.

Now with computers becoming more and more complex and capable we are faced with the question why should we measure software engineering? Companies are seeing 5 measurable benefits of technological adaptation, increasing speed to knowledge via the internet, reduced communication costs via emails and other networking media, reduced travel costs with remote work becoming more and more popular especially throughput the COVID-19 pandemic, increasing speed to access internal experts also via email and networking media and finally increasing employee satisfaction and happiness [4].
With more and more fields becoming reliant on new and old software we face the problem of is this software upto standard and does it meet security requirements. In order to ensure the specifications of the software are met we need to measure the software engineering process and I think it is crucial that we do this accurately as a breach in security could potentially damage, if not entirely take down, not only a company but also the financial service, government sectors and any other major area if a major corruption, fault or hack was to occur. There are many ways in which the software engineering process can be measured in terms of measurable data but first we must understand how we can measure the software engineering process. First step in measuring the process is to measure where the team is today and use it as a benchmark. This benchmark can be compared against previous projects to see who works best together under certain circumstances, but crucially it needs to be used to compare against future projects where measuring is occurring in order to see progress. Measuring software engineering can determine the quality and productivity of the current software delivery process and identify areas of improvement, predict the quality and progress of the software development projects and also better manage workloads and priorities between teams and team members.  While measuring software engineering theoretically is not that difficult of a task but to implement a program to measure it is a whole other ball game but that will be talked about in more detail later on. Measuring software engineering can be done in numerous ways.<br/>
    1) Project or sprint burndown - a burndown can monitor the project scope creep, keep the team running on schedule and  compare the planned work against the team progression. This can all then be graphed into a burnout graph.<br/>
    2) Ticket close rate - the time between the creation of a ticket and the closing of the ticket. <br/>
    3) Code Churn -  rewriting small amounts of code. It tells us where we are spending the most time in the code, making updates, adding features, fixing defects. The higher the churn, the more time the team spends in that area of the code. The more time spent in an area of code, the more risk there is if the code is low quality or doesn’t have good coverage[5].<br/>
    4) Code refactoring - similar to code churning but it does affect code quality, it is essentially rewriting small snippets of code in order to maintain/improve on clarity and simplicity without changing its behaviour.<br/>
    5) Lead time - the time it takes between the initiation and completion of a product.<br/>
    6) Cycle time - the time it takes to complete a single task. <br/>
    * Deployment and commit frequency 
        How frequent a major code change/ deployment is committed/released.<br/>
    * Change failure percentage 
        Simply the measure of failures in a code change so how many things has this change broken.<br/>
    * Mean time between failures
        The average time between system breakdowns. This is crucial in measuring metrics for performance, safety and design.<br/>
    * Mean time to recover/repair 
        The average time it takes to correct a failure. This can measure employee productivity as it shows how quick they can solve a problem but can also measure metrics for performance, safety and design.<br/>

Now that we have discussed how to measure software engineering we need to be able to the rules on tracking software engineering efficiency. Tracking software efficiency is important as it tells us how the 10 points above interact with each other to give us measurable data and also following these rules will result in a safe, efficient, understandable and clear program. There are 7 rules to follow when measuring efficiency 
Software metrics should be easy to understand and code should be easy to understand and well commented/documented.
Software metrics should be lined with business priorities. The more things you measure the lesser importance each thing gets, only measuring crucial things to the scope like reduced number of bugs, number of software iterations, software efficiency and speed of completion of tasks.
Numbers should not be tracked rather trends should be. Tracking numbers can be inaccurate as the number of commits/bug fixes/ lines added etc can vary depending on the task and program at hand. Rather the trend of how many commits are being made in the phase should be compared against other projects and other related phases in the same project. Numbers can also be deceiving as coding does not consist of purely writing code and committing it, for example when I have a coding assignment to do for college I might spend one day researching the problem before I even sit down and code. I also always start the day with less complex tasks such as the first thing into my college day. I will watch the easier lectures and ready myself for the more complex tasks.
Set shorter time intervals as most sprints are weekly or biweekly so measurements should be less than that so the team has sufficient time to have enough data to iterate at each sprint.
Don't use software metrics that don't result in change, there is no point measuring data that will not affect the outcome. This is like training Christiano Ronaldo to be a goalkeeper, it is a waste of resources as it will realistically never happen.
Metrics do not tell you the whole story, metrics are to be used as talking points and are not to be used ro make harsh decisions. People can be unproductive for a number of reasons, metrics should be used to identify a cause and get to the root of it.
Don't use any metrics for individual for individual performance, programming is a group effort metrics tell the story of the team not an individual. In some projects an individual may be less involved than in others (i.e. bug fixing takes a lot less code than the initial commits so the individual would have a seemingly unproductive project but in fact bug testing is most often the most infuriating and difficult part of  a project)[6]

While these are the metrics we should be measuring to measure software engineering, how do these tie in together to create an algorithmic approach to measuring software engineering? While we cant use the metrics above to measure an individual's performance that isn't a problem as we are not trying to measure an individual's contribution, we are trying to measure how the team designed and developed their project and thus can deduct once these measurements have been established how an individual may have performed. There are 8 metrics to measure when we discuss an algorithmic approach to how to measure our software engineering process.
Code quality. We must be able to maintain the software code quality by writing bug-free and semantically correct code.
Reliability. Reliability can be checked against the MTBF and the MTTR and is very important as a good software program should not behave differently under the same conditions and crashes should be as infrequent as possible.
Performance. Measuring the performance of the software by determining whether the software meets all the customers demands.
Usability. The software must be easy to use as a user is not always going to be tech literate so the UI should be as simple and straightforward as possible without losing any functionality.
Correctness. The system or software should work correctly without an errors by satisfying the user
Maintainability. The software should be easy to maintain even if a new team is put on the project. This includes minimal time required between adaptation of new features/functionality, Mean time to change (MTTC) and performance under a new environment.
Integrity. Software should be easy to integrate with other required software which increases the software functionality. (i.e. if a graphing function of data was to be added in the future the software should provide no [problems to this new feature upon initial release, even if the customer never specified the intent to add this functionality).
Security. On launch the software should be secure to assure that there are no unauthorized changes (no fear of cyber attacks or hacks etc… ) especially under circumstances where the software contains sensitive data about a person or company

We have many tools now today to measure the software engineering process and make the lives of not only software engineers but also their managers (whether traditional or non-traditional) easier. A lot of these emerged in the late 2000s but became common practice in the early 2010s due to the increasing capability and complexity of computers stemming from the second wave of AI, these new developments allowed for the development of these super useful tools that a lot of us depend on today. As I have mentioned already back in this 1980s a report called PSP was used to measure software engineering, however this was not adopted into common practice as it required a lot of manual work so the team who developed it decided to create a new and improved PSP that would require less manual work and more automation in a computer program. This saw the adaptation of PSP in many new places including personal programmers, students and large companies but it was still not perfect, however it did begin a wave of the development of  similar products that would soon become a requirement to use for software engineers. The most popular tools for measuring software engineering is Github Insights, not only is insights very easy to access due to its integration into Github already. But it also contains complex data and algorithms to display effort and productivity on voth a team and individual level. Insights provides in-depth but yet easy to understand information into a variety of factors. You can view an overview of a repository's activity through Pulse. Pulse includes a list of open and merged pull requests, open and closed issues, and a graph showing the commit activity for the top 15 users who committed to the default branch of the project in the selected time period (which can be set from a range between 1hr and 1 month).[7] Contributors will display a graph of total contributions to a repository and also separate  graphs of individual contributions, displaying the total number of commits, lines added and lines deleted. It can also display traffic to a certain repository which will tell you how many views and unique views have been on this repository and also pulls that have been made from this repository. The total number of commits to a project can be seen on a weekly basis for the year or daily over the past week. The frequency of code deletion and insertion can also be viewed on a graph. The entire network of branches and main can be viewed in the network graph, this is especially helpful to track who is doing what, when they started and what they have added. A list of all the forks can also be seen which is a copy of a repository which allows for freely experimentation with the code and no worries of entirely breaking something. Finally the dependencies graph can also be seen so see where a dependency is and who introduced the dependency. While the majority of these tools are used for ease to the developer and not to measure software engineering I do think it is a good way to understand where the team is at, what they are doing and how productive they are being. There is also a tool developed by PluralSight called Flow which allows you to “see your team like never before”. Unlike Github insights Flow uses the metrics discussed above with the aim of measuring the development, it allows a manager to see how much time is spent refactoring code, recognizing bottlenecks and eliminating them, get concrete data about commits, recognise if code reviews are productive, scan for uncertainty and disagreement amongst team members, observe team dynamic,measure what percentage of commits get zero responses, measure the percentage of the time is involved in feedback, tell if seniors engineers are providing feedback, see where the team are efficient and where they could use a managers help[8]. A software called waydev can also measure software engineering and they believe that in the coming decade the AGILE development idea will be replaced with their new reporting technique. Their reporting ideology is based on 3 factors Daily standups, one to one meetings and code review workflow. The daily standup gets a single view of the teams contributions and work habits, can give details into commits and pull requests and can set expectations proactively. These details are then displayed on graphs and can be viewed by a manager. These daily standups also so not necessarily need to include the team as well as a report is automatically generated instead of the team informing the manager on their individual progress and expectations.  One to One meetings give valuable insights into each engineer and can help you direct an individual easily. Graphs can display accurate metrics to assist you in identifying where a problem may lie. The code review workflow segment will allow the manager to learn what is going on in the code review process to optimize collaboration and gain a bird's eye view on commit and pull request activity. The main idea for Waydev was they wanted to generate automated reports on real time data in  order to save engineers and managers from creating reports and presenting them to managers daily.[9] Code climate gives end to end visibility into continuous delivery on a daily workflow basis and also an overview. It can also display the full context on where your team is working, striking a balance between code review speed and thoroughness. It also keeps an activity track log to check in on how work is distributed and who is working on what. It can also provide flexibility to focus on your temas unique challenges, providing graphed data against an individual's different tasks.The complex report builder tool can display deeper questions about the data at hand. While these are the tools that are entirely based on measuring software engineering there are also lesser tools that can tell alot about your software such as the inbuilt test classes in a program language. These tests can display helpful data such as time to run and correctness under certain cases.  There are many types of test classes such as Unit Tests, Integration Tests, Functional Tests, End-to-End tests and many more which once all used in collaboration can give us details about the software at hand that we would not be able to check manually. There are also tools to analyze our code such as Helix QAC for C and C++ and also Klocwork for C, C# and Java. These tools can determine code compliance, safe secure and reliable code resulting in higher quality code and faster releases.
 
With tech companies taking more care into creating a health working environment and creating happy productive employees, especially the FANGs companies, providing break rooms with the option to play video games, ping-pong, have coffee or a beer in some places or even attend the gym. Due to the massive success of these companies taking care of employee mental health we are seeing serious developments in the computational platforms available to measure employees health, happiness and productivity. Wearable measuring technology will transform corporate accounting, production, and human resource systems at a fundamental level . It has been found that people who are happy have 37% higher work productivity and 300% higher creativity. They also enjoy higher annual income, faster promotion, and are more likely to have a successful marriage, have friends, and to live longer and healthier lives [10]. We have all heard of Fitbit and Apple Watch which can track activity throughout the day for personal use. But these technologies can also be used on employees to measure their productivity. If an employer was to give an employee a Fitbit and get consent to measure the data, as studies have shown there is a strong correlation between exercise and productivity and also mood. So if an employer was to measure the exercise, sleeping quality and pattern and also even heart rate they could then determine if an employee is being productive and what they need to do in order to encourage productivity. Humanyze is a lesser known device that measures productivity, Humanzye is an employee identity card however it is fitted with sensors that can measure the amount and direction of movement in 3 dimensions. The device can also measure tone of conversation and use AI to establish numerous things such as what kind of worker you are (i.e. motivator, problem solver, helper etc…) and also the mood you are in. Humanyze can also display graphed data on how your teams interact with each other both for business reasons and leisure. A new technology that is yet to be heavily implemented are chairs that can measure the breathing rate, heart rate and posture to tell if an employee is stressed and inform them that a break is needed.  There is also non wearable tech that can both measure productivity and mood of the room rather than an individual then in  collaboration with other tech change the environment in order to create a more productive scene. I was listening to a podcast called Sleepwalkers a few weeks ago and they were talking about how a movie production company was experimenting with using carbon dioxide detectors to see how the viewers are biologically reacting with the move. I don't know the full science behind this but it was basically using the amount of carbon dioxide in the air to determine if a scene in the movie that was supposed to cause anticipation was in fact inducing anxiety into the viewers as anxiety can change the breathing rate and thus carbon dioxide production of the viewers. They also experimented with other chemical detectors to happiness, distraught and fear and were successful in doing so thus being able to understand why a scene may cause these emotions. I found them talking about this very interesting as I immediately thought in  relation to this report that companies may be doing that in their offices, while measuring these moods alone may not lead to productivity the data could be used in collaboration with other tech such as air conditioning in order to control the temperature to calm or even encourage employees. It could also be used to change maybe the colour of lights in the room to a more blue shade to calm the room or red to lead to more productivity. The 20th century was characterized by people having to adjust to systems and rules. The future, in contrast, will see the level of individual happiness enhanced through artificial intelligence and the quantification of happiness, with systems and rules having to adjust to people[10].

“There is an ethical dimension to this that has to be sorted out,” believes Michael Meyer, professor of philosophy at Santa Clara University. “We are at the front end of new territory, but the risks are genuine” [11]. When we talk about measuring data regardless of if they are software tools or hardware tools we face many serious ethics concerns around our liberty, security and privacy. On a software level the biggest concern is the security of confidential business data, user stored data in a database and the security of the code itself. Questions to be asked are do these programs bring risks that may jeopardise our security? Do the programs inject code into our programs that may cause the data to be corrupt? And also do these programs present any types of risks to our company policy and principles? While all of these points are on a company basis there is also, in my opinion, the more significant ethics behind the storage and usage  of the individuals data. The biggest ethical concern is who has access to this data, uncertainty behind who is able to view and access this information may lead to employees being much less productive due to the stress and worry they would encounter under constant surveillance. We also face the problem of are future employers allowed to request access to this data if they are considering us for a job, I think this is a scary thought as we could be denied a possible job not because of our work ethic but actually because of our productivity (which can be impacted by a number of external factors) in another role. I think with all these software tools employers need to be very careful with how they use the data and where they store the data and the government needs to enforce strict laws against the misuse and missharing or data. This is especially significant in the field of software engineering as I find a lot of my inspiration comes when I am not even thinking about work, like I have had countless realisations of how to design an algorithm to do a task while I have been eating my breakfast or going for a walk and I am not the only one who gets this as well i have enquired with numerous classmates who feel the same way. Employers also need to remember that software engineering is a team effort and no individual has a key role in every project. By this I mean the metrics I mentioned above in how to measure software engineering and program efficiency measures the work of the entire team and from this data the work of an individual can be derived, but this derivation does not necessarily reflect the entire work of the individual. In a software project there are many ways of being productive and helping the team without writing major amounts of code. I used debugging as an example where i previously talked about this but i think it is crucial to keep in mind that programing is split up into many different  tasks from designing, coding, debugging testing and clean up just because a programmer did not write many lines of code or didn't cut the time to run significantly it does not mean they are being unproductive. I think a much more ethical approach to the usage of these tools would be instead of measuring productivity and code effectiveness (of course code effectiveness needs to be measured but I don't think it should be linked to an individuals contribution) these tools should measure one's ability to fully understand the scope of work, the problems faced, scope of importance etc… and it should be used to gauge whether or not the employee has been unproductive due to misunderstanding of requirements and then the data can be used to get to the bottom of the issue and solve the problem. Those creating and using these tools emphasise that the focus should be on individual employees understanding, and therefore improving, themselves and by extension the performance of the wider organisation [11]
While the ethics concerns with software tools are abundant and not to be taken lightly, the hardware tools that are measuring our personal activity, sleep, emotions etc… are a whole different ball game. Once again the security of this data is the main concern. This data is measuring an individual's health and emotions and I think the security of this data is possibly more important than the security of company data. With  this constant surveillance do we lose our freedom, are we being tracked even in the bathroom, do we lose our right to free speech? Is it even fair to share this data with our employers? I think an ethical approach to the use of wearable tech in a workplace would involve not sharing the exact data with an employer but rather the tech using the data gathered in order to alert the manager that an employee needs a break or holiday without distributing any data to the employer. The possibilities are endless with tech like this, it could even be implemented so when the data portrays extreme stress or even lack of productivity due to lack of exercise it could cause a lock on the employees computer, thus encouraging them to take a break, go for a walk or even have a chat with a friend all without sharing the data with an employer. This type of tech is so powerful especially when it is enforced in a way that is off the clock and still recording data. These tools should be used to tell when people are over-working, over-stressed etc… and need to be granted a day off rather than being used for an employer to judge whether or not they want an employee under their payroll.

With the emergence of all this new measuring technology for software engineering we need to find an ethical way of carrying out surveillance that does not jeopardise and employees human rights. We also need to keep into account that programming consists of various tasks so measuring productivity for software engineers presents a difficult task as the tools we use measure the project as a whole and then derive the individuals data from that and the changes they made so the data is not always wholly accurate. We need to be morally correct in the way we use this data, the way we store it and also the way we share it. If wearable tech is being used in order to measure data we need to be even more careful and moral  in the way we use this data as this data could be shared with insurance companies to increase insurance costs on an individual  and the question that presents on ethics deserves an essay in itself.The ethical measuring of this sort of data could have many benefits but in order to encounter these benefits we must execute it properly. These benefits include both working environment and employee lifestyles. Changes in the office could range from a higher EQ (emotional intelligence) due to more satisfied workers thus boosting productivity as they are more aware of when they are stressed, overworked, tired etc...Workers lifestyles would say major changes as well, they would be happier at work as they know the technology is looking out for the best decisions for them thus resulting in productivity. This boost in productivity would result in them potentially spending more time at home with their families and being overall more satisfied.


[1] - http://www.nextlearning.nl/wp-content/uploads/sites/11/2015/02/McKinsey-on-Impact-social-technologies.pdf

[2] - https://anabaptistworld.org/avatar-goes-church/

[3] -  P.M. Johnson et al., “Beyond the Personal Software Process: Metrics Collection and Analysis for the Differently Disciplined,” Page 1 - Introduction. 
https://www.researchgate.net/publication/4016775_Beyond_the_Personal_Software_Process_Metrics_collection_and_analysis_for_the_differently_disciplined

[4] - http://www.nextlearning.nl/wp-content/uploads/sites/11/2015/02/McKinsey-on-Impactsocial-technologies.pdf

[5] - https://medium.com/@0utsider/code-churn-7ba0fe6aec6c

[6] All of these points are paraphrased from 
https://hackernoon.com/how-to-use-and-not-abuse-software-engineering-metrics-3i11530tr

[7] - https://docs.github.com/en/enterprise-server@2.20/github/visualizing-repository-data-with-graphs/viewing-a-summary-of-repository-activity

[8] - These points are paraphrased from - https://www.pluralsight.com/product/flow

[9] - These points are paraphrased from - https://waydev.co/

[10] - http://www.hitachi.com/rev/pdf/2015/r2015_08_116.pdf

[11] - https://www.hrmagazine.co.uk/article-details/the-ethics-of-gathering-employee-data
